Logs - ETL

￼

Follow the troubleshooting link:

https://chatgpt.com/share/6895410c-6c30-8000-bc3f-d3a9c8ad6133



An exception or error caused a run to abort: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x527e5409) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x527e5409 java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x527e5409) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x527e5409 at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala:213) at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:114) at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:353) at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:290) at org.apache.spark.SparkEnv$.create(SparkEnv.scala:339) at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:194) at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:279) at org.apache.spark.SparkContext.<init>(SparkContext.scala:464)

  
 
/Library/Java/JavaVirtualMachines/openjdk-17.jdk/Contents/Home/bin/java --add-opens java.base/sun.nio.ch=ALL-UNNAMED "-javaagent:/Applications/IntelliJ IDEA CE.app/Contents/lib/idea_rt.jar=52928" -Dfile.encoding=UTF-8 -classpath "/Users/dhandapanidhandapaniyedappalli/Library/Application Support/JetBrains/IdeaIC2025.1/plugins/Scala/lib/runners.jar:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/target/scala-2.13/test-classes:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/target/scala-2.13/classes:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.13.8/scala-library-2.13.8.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql_2.13/3.3.1/spark-sql_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-core_2.13/3.3.1/spark-core_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/postgresql/postgresql/42.7.0/postgresql-42.7.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalactic/scalactic_2.13/3.2.18/scalactic_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.20.3/rocksdbjni-6.20.3.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/2.9.1/univocity-parsers-2.9.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.13/3.3.1/spark-sketch_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.13/3.3.1/spark-catalyst_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-tags_2.13/3.3.1/spark-tags_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parallel-collections_2.13/1.0.3/scala-parallel-collections_2.13-1.0.3.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-core/1.7.6/orc-core-1.7.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.7.6/orc-mapreduce-1.7.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hive/hive-storage-api/2.7.2/hive-storage-api-2.7.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.12.2/parquet-column-1.12.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.12.2/parquet-hadoop-1.12.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.13.4.1/jackson-databind-2.13.4.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/xbean/xbean-asm9-shaded/4.20/xbean-asm9-shaded-4.20.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro/1.11.0/avro-1.11.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.11.0/avro-mapred-1.11.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill_2.13/0.10.0/chill_2.13-0.10.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill-java/0.10.0/chill-java-0.10.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.2/hadoop-client-api-3.3.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.2/hadoop-client-runtime-3.3.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.13/3.3.1/spark-launcher_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.13/3.3.1/spark-kvstore_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.13/3.3.1/spark-network-common_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.13/3.3.1/spark-network-shuffle_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.3.1/spark-unsafe_2.13-3.3.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.6.2/zookeeper-3.6.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/servlet/jakarta.servlet-api/4.0.3/jakarta.servlet-api-4.0.3.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.12.0/commons-lang3-3.12.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-text/1.9/commons-text-1.9.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-collections4/4.4/commons-collections4-4.4.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.32/jul-to-slf4j-1.7.32.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.32/jcl-over-slf4j-1.7.32.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/logging/log4j/log4j-slf4j-impl/2.17.2/log4j-slf4j-impl-2.17.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.17.2/log4j-api-2.17.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/logging/log4j/log4j-core/2.17.2/log4j-core-2.17.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/logging/log4j/log4j-1.2-api/2.17.2/log4j-1.2-api-2.17.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/ning/compress-lzf/1.1/compress-lzf-1.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/luben/zstd-jni/1.5.2-1/zstd-jni-1.5.2-1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.9.25/RoaringBitmap-0.9.25.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.13/2.1.0/scala-xml_2.13-2.1.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.13.8/scala-reflect-2.13.8.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-jackson_2.13/3.7.0-M11/json4s-jackson_2.13-3.7.0-M11.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.36/jersey-client-2.36.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.36/jersey-common-2.36.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.36/jersey-server-2.36.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.36/jersey-container-servlet-2.36.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.36/jersey-container-servlet-core-2.36.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/inject/jersey-hk2/2.36/jersey-hk2-2.36.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-all/4.1.74.Final/netty-all-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/clearspring/analytics/stream/2.9.6/stream-2.9.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.2.7/metrics-core-4.2.7.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/4.2.7/metrics-jvm-4.2.7.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/4.2.7/metrics-json-4.2.7.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/4.2.7/metrics-graphite-4.2.7.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jmx/4.2.7/metrics-jmx-4.2.7.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.13/2.13.4/jackson-module-scala_2.13-2.13.4.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/ivy/ivy/2.5.0/ivy-2.5.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/razorvine/pickle/1.2/pickle-1.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.9.5/py4j-0.10.9.5.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/checkerframework/checker-qual/3.31.0/checker-qual-3.31.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.13/1.1.2/scala-parser-combinators_2.13-1.1.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.16/janino-3.0.16.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.16/commons-compiler-3.0.16.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.8/antlr4-runtime-4.8.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-vector/7.0.0/arrow-vector-7.0.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-netty/7.0.0/arrow-memory-netty-7.0.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-shims/1.7.6/orc-shims-1.7.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.14.0/protobuf-java-3.14.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/airlift/aircompressor/0.21/aircompressor-0.21.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.12.2/parquet-common-1.12.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.12.2/parquet-encoding-1.12.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-format-structures/1.12.2/parquet-format-structures-1.12.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.12.2/parquet-jackson-1.12.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-ipc/1.11.0/avro-ipc-1.11.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/crypto/tink/tink/1.6.1/tink-1.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/zookeeper/zookeeper-jute/3.6.2/zookeeper-jute-3.6.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/shims/0.9.25/shims-0.9.25.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.13/3.7.0-M11/json4s-core_2.13-3.7.0-M11.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.25.0-GA/javassist-3.25.0-GA.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-buffer/4.1.74.Final/netty-buffer-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-codec/4.1.74.Final/netty-codec-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-common/4.1.74.Final/netty-common-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-handler/4.1.74.Final/netty-handler-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-tcnative-classes/2.0.48.Final/netty-tcnative-classes-2.0.48.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-resolver/4.1.74.Final/netty-resolver-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport/4.1.74.Final/netty-transport-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-classes-epoll/4.1.74.Final/netty-transport-classes-epoll-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-native-unix-common/4.1.74.Final/netty-transport-native-unix-common-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-classes-kqueue/4.1.74.Final/netty-transport-classes-kqueue-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-native-kqueue/4.1.74.Final/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-native-kqueue/4.1.74.Final/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-format/7.0.0/arrow-format-7.0.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-core/7.0.0/arrow-memory-core-7.0.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/flatbuffers/flatbuffers-java/1.12.0/flatbuffers-java-1.12.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/tukaani/xz/1.9/xz-1.9.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/gson/gson/2.8.6/gson-2.8.6.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.13/3.7.0-M11/json4s-ast_2.13-3.7.0-M11.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.13/3.7.0-M11/json4s-scalap_2.13-3.7.0-M11.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest_2.13/3.2.18/scalatest_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-core_2.13/3.2.18/scalatest-core_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-featurespec_2.13/3.2.18/scalatest-featurespec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-flatspec_2.13/3.2.18/scalatest-flatspec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-freespec_2.13/3.2.18/scalatest-freespec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-funsuite_2.13/3.2.18/scalatest-funsuite_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-funspec_2.13/3.2.18/scalatest-funspec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-propspec_2.13/3.2.18/scalatest-propspec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-refspec_2.13/3.2.18/scalatest-refspec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-wordspec_2.13/3.2.18/scalatest-wordspec_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-diagrams_2.13/3.2.18/scalatest-diagrams_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-matchers-core_2.13/3.2.18/scalatest-matchers-core_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-shouldmatchers_2.13/3.2.18/scalatest-shouldmatchers_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-mustmatchers_2.13/3.2.18/scalatest-mustmatchers_2.13-3.2.18.jar:/Users/dhandapanidhandapaniyedappalli/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scalatest/scalatest-compatible/3.2.18/scalatest-compatible-3.2.18.jar" org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner @/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/idea_scala_test_runner17296414834484663477.tmp -showProgressMessages true
Testing started at 05:37 ...


Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/08/08 05:37:04 WARN Utils: Your hostname, Dhandapanis-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.2.100 instead (on interface en0)
25/08/08 05:37:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/08/08 05:37:04 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/08/08 05:37:04 INFO ResourceUtils: ==============================================================
25/08/08 05:37:04 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:04 INFO ResourceUtils: ==============================================================
25/08/08 05:37:04 INFO SparkContext: Submitted application: ForbesCleaner-Test
25/08/08 05:37:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:04 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:04 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:04 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:04 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:04 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:04 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:04 INFO Utils: Successfully started service 'sparkDriver' on port 52932.
25/08/08 05:37:04 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:04 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:04 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-01cc3942-c0db-46c0-a95d-68840abbbe9f
25/08/08 05:37:05 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:05 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:05 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:05 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52933.
25/08/08 05:37:05 INFO NettyBlockTransferService: Server created on 192.168.2.100:52933
25/08/08 05:37:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52933, None)
25/08/08 05:37:05 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52933 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52933, None)
25/08/08 05:37:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52933, None)
25/08/08 05:37:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52933, None)

25/08/08 05:37:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:05 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:06 INFO CodeGenerator: Code generated in 40.367416 ms
25/08/08 05:37:06 INFO CodeGenerator: Code generated in 10.493333 ms
25/08/08 05:37:06 INFO CodeGenerator: Code generated in 3.050209 ms
25/08/08 05:37:06 INFO DAGScheduler: Registering RDD 2 (count at ForbesAnalyzerTest.scala:42) as input to shuffle 0
25/08/08 05:37:06 INFO DAGScheduler: Got map stage job 0 (count at ForbesAnalyzerTest.scala:42) with 2 output partitions
25/08/08 05:37:06 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at ForbesAnalyzerTest.scala:42)
25/08/08 05:37:06 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:06 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:06 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at ForbesAnalyzerTest.scala:42), which has no missing parents
25/08/08 05:37:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52933 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at ForbesAnalyzerTest.scala:42) (first 15 tasks are for partitions Vector(0, 1))
25/08/08 05:37:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
25/08/08 05:37:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:06 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
25/08/08 05:37:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1971 bytes result sent to driver
25/08/08 05:37:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1971 bytes result sent to driver
25/08/08 05:37:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 63 ms on 192.168.2.100 (executor driver) (1/2)
25/08/08 05:37:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 58 ms on 192.168.2.100 (executor driver) (2/2)
25/08/08 05:37:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:06 INFO DAGScheduler: ShuffleMapStage 0 (count at ForbesAnalyzerTest.scala:42) finished in 0.313 s
25/08/08 05:37:06 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:06 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:06 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:06 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:06 INFO CodeGenerator: Code generated in 5.130708 ms
25/08/08 05:37:07 INFO SparkContext: Starting job: count at ForbesAnalyzerTest.scala:42
25/08/08 05:37:07 INFO DAGScheduler: Got job 1 (count at ForbesAnalyzerTest.scala:42) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 2 (count at ForbesAnalyzerTest.scala:42)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at ForbesAnalyzerTest.scala:42), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52933 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at ForbesAnalyzerTest.scala:42) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2745 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 2 (count at ForbesAnalyzerTest.scala:42) finished in 0.033 s
25/08/08 05:37:07 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 1 finished: count at ForbesAnalyzerTest.scala:42, took 0.037336 s
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 2.907834 ms
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 8 (count at ForbesAnalyzerTest.scala:45) as input to shuffle 1
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 2 (count at ForbesAnalyzerTest.scala:45) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at ForbesAnalyzerTest.scala:45)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at ForbesAnalyzerTest.scala:45), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52933 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at ForbesAnalyzerTest.scala:45) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1928 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 8 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 3 (count at ForbesAnalyzerTest.scala:45) finished in 0.011 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO SparkContext: Starting job: count at ForbesAnalyzerTest.scala:45
25/08/08 05:37:07 INFO DAGScheduler: Got job 3 (count at ForbesAnalyzerTest.scala:45) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 5 (count at ForbesAnalyzerTest.scala:45)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at ForbesAnalyzerTest.scala:45), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52933 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at ForbesAnalyzerTest.scala:45) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 2745 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 5 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 5 (count at ForbesAnalyzerTest.scala:45) finished in 0.013 s
25/08/08 05:37:07 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 3 finished: count at ForbesAnalyzerTest.scala:45, took 0.014275 s
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.2.100:52933 in memory (size: 5.6 KiB, free: 3.4 GiB)

25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.2.100:52933 in memory (size: 5.6 KiB, free: 3.4 GiB)

25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.2.100:52933 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.612667 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 32.084291 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.660708 ms
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 14 (head at ForbesAnalyzerTest.scala:62) as input to shuffle 2
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 4 (head at ForbesAnalyzerTest.scala:62) with 3 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (head at ForbesAnalyzerTest.scala:62)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[14] at head at ForbesAnalyzerTest.scala:62), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.8 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.2.100:52933 (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[14] at head at ForbesAnalyzerTest.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 6.0 with 3 tasks resource profile 0
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.2.100:52933 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 6) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 7) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
25/08/08 05:37:07 INFO Executor: Running task 2.0 in stage 6.0 (TID 7)
25/08/08 05:37:07 INFO Executor: Running task 1.0 in stage 6.0 (TID 6)
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.704167 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 2.447875 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 2.093 ms
25/08/08 05:37:07 INFO Executor: Finished task 1.0 in stage 6.0 (TID 6). 2543 bytes result sent to driver
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 2543 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 6) in 39 ms on 192.168.2.100 (executor driver) (1/3)
25/08/08 05:37:07 INFO Executor: Finished task 2.0 in stage 6.0 (TID 7). 2543 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 39 ms on 192.168.2.100 (executor driver) (2/3)
25/08/08 05:37:07 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 7) in 40 ms on 192.168.2.100 (executor driver) (3/3)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 6 (head at ForbesAnalyzerTest.scala:62) finished in 0.046 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 5.902459 ms
25/08/08 05:37:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 8.520375 ms
25/08/08 05:37:07 INFO SparkContext: Starting job: head at ForbesAnalyzerTest.scala:62
25/08/08 05:37:07 INFO DAGScheduler: Got job 5 (head at ForbesAnalyzerTest.scala:62) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 8 (head at ForbesAnalyzerTest.scala:62)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[18] at head at ForbesAnalyzerTest.scala:62), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 27.3 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.2.100:52933 (size: 12.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.2.100:52933 in memory (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at head at ForbesAnalyzerTest.scala:62) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 3 (216.0 B) non-empty blocks including 3 (216.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 6036 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 25 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 8 (head at ForbesAnalyzerTest.scala:62) finished in 0.031 s
25/08/08 05:37:07 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 5 finished: head at ForbesAnalyzerTest.scala:62, took 0.033403 s
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.418333 ms
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 21 (head at ForbesAnalyzerTest.scala:63) as input to shuffle 3
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 6 (head at ForbesAnalyzerTest.scala:63) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (head at ForbesAnalyzerTest.scala:63)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[21] at head at ForbesAnalyzerTest.scala:63), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 24.9 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.2.100:52933 (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[21] at head at ForbesAnalyzerTest.scala:63) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.2.100:52933 in memory (size: 12.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 14 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 9 (head at ForbesAnalyzerTest.scala:63) finished in 0.020 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/08/08 05:37:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/08/08 05:37:07 INFO SparkContext: Starting job: head at ForbesAnalyzerTest.scala:63
25/08/08 05:37:07 INFO DAGScheduler: Got job 7 (head at ForbesAnalyzerTest.scala:63) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 11 (head at ForbesAnalyzerTest.scala:63)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[24] at head at ForbesAnalyzerTest.scala:63), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 25.5 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.2.100:52933 (size: 11.5 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.2.100:52933 in memory (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[24] at head at ForbesAnalyzerTest.scala:63) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 11.0 (TID 10)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 11.0 (TID 10). 3655 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 6 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 11 (head at ForbesAnalyzerTest.scala:63) finished in 0.013 s
25/08/08 05:37:07 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 7 finished: head at ForbesAnalyzerTest.scala:63, took 0.015409 s
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 27 (head at ForbesAnalyzerTest.scala:67) as input to shuffle 4
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 8 (head at ForbesAnalyzerTest.scala:67) with 4 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (head at ForbesAnalyzerTest.scala:67)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[27] at head at ForbesAnalyzerTest.scala:67), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 24.9 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.2.100:52933 (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.2.100:52933 in memory (size: 11.5 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[27] at head at ForbesAnalyzerTest.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 12) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 13) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 14) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 2.0 in stage 12.0 (TID 13)
25/08/08 05:37:07 INFO Executor: Running task 1.0 in stage 12.0 (TID 12)
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
25/08/08 05:37:07 INFO Executor: Running task 3.0 in stage 12.0 (TID 14)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 14 ms on 192.168.2.100 (executor driver) (1/4)
25/08/08 05:37:07 INFO Executor: Finished task 3.0 in stage 12.0 (TID 14). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 14) in 15 ms on 192.168.2.100 (executor driver) (2/4)
25/08/08 05:37:07 INFO Executor: Finished task 1.0 in stage 12.0 (TID 12). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 12) in 17 ms on 192.168.2.100 (executor driver) (3/4)
25/08/08 05:37:07 INFO Executor: Finished task 2.0 in stage 12.0 (TID 13). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 13) in 18 ms on 192.168.2.100 (executor driver) (4/4)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 12 (head at ForbesAnalyzerTest.scala:67) finished in 0.023 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/08/08 05:37:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/08/08 05:37:07 INFO SparkContext: Starting job: head at ForbesAnalyzerTest.scala:67
25/08/08 05:37:07 INFO DAGScheduler: Got job 9 (head at ForbesAnalyzerTest.scala:67) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 14 (head at ForbesAnalyzerTest.scala:67)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[31] at head at ForbesAnalyzerTest.scala:67), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.3 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.2.100:52933 (size: 12.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[31] at head at ForbesAnalyzerTest.scala:67) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.2.100:52933 in memory (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 4 (288.0 B) non-empty blocks including 4 (288.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 5993 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 7 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 14 (head at ForbesAnalyzerTest.scala:67) finished in 0.012 s
25/08/08 05:37:07 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 9 finished: head at ForbesAnalyzerTest.scala:67, took 0.013131 s
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 34 (head at ForbesAnalyzerTest.scala:70) as input to shuffle 5
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 10 (head at ForbesAnalyzerTest.scala:70) with 4 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (head at ForbesAnalyzerTest.scala:70)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[34] at head at ForbesAnalyzerTest.scala:70), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 24.9 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.2.100:52933 (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[34] at head at ForbesAnalyzerTest.scala:70) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks resource profile 0
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.2.100:52933 in memory (size: 12.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 17) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 18) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 19) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
25/08/08 05:37:07 INFO Executor: Running task 3.0 in stage 15.0 (TID 19)
25/08/08 05:37:07 INFO Executor: Running task 1.0 in stage 15.0 (TID 17)
25/08/08 05:37:07 INFO Executor: Running task 2.0 in stage 15.0 (TID 18)
25/08/08 05:37:07 INFO Executor: Finished task 3.0 in stage 15.0 (TID 19). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 19) in 13 ms on 192.168.2.100 (executor driver) (1/4)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 14 ms on 192.168.2.100 (executor driver) (2/4)
25/08/08 05:37:07 INFO Executor: Finished task 1.0 in stage 15.0 (TID 17). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 17) in 14 ms on 192.168.2.100 (executor driver) (3/4)
25/08/08 05:37:07 INFO Executor: Finished task 2.0 in stage 15.0 (TID 18). 2500 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 18) in 15 ms on 192.168.2.100 (executor driver) (4/4)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 15 (head at ForbesAnalyzerTest.scala:70) finished in 0.020 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 2.238708 ms
25/08/08 05:37:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/08/08 05:37:07 INFO SparkContext: Starting job: head at ForbesAnalyzerTest.scala:70
25/08/08 05:37:07 INFO DAGScheduler: Got job 11 (head at ForbesAnalyzerTest.scala:70) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 17 (head at ForbesAnalyzerTest.scala:70)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[38] at head at ForbesAnalyzerTest.scala:70), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 27.3 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.2.100:52933 (size: 12.3 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.2.100:52933 in memory (size: 11.2 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[38] at head at ForbesAnalyzerTest.scala:70) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 20) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 17.0 (TID 20)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 4 (288.0 B) non-empty blocks including 4 (288.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 17.0 (TID 20). 5993 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 20) in 12 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 17 (head at ForbesAnalyzerTest.scala:70) finished in 0.017 s
25/08/08 05:37:07 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 11 finished: head at ForbesAnalyzerTest.scala:70, took 0.018954 s


25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.269166 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 6.794292 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.645125 ms
25/08/08 05:37:07 INFO SparkContext: Starting job: count at ForbesAnalyzerTest.scala:95
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 42 (count at ForbesAnalyzerTest.scala:95) as input to shuffle 6
25/08/08 05:37:07 INFO DAGScheduler: Got job 12 (count at ForbesAnalyzerTest.scala:95) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 19 (count at ForbesAnalyzerTest.scala:95)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[42] at count at ForbesAnalyzerTest.scala:95), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.8 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.2.100:52933 (size: 5.7 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[42] at count at ForbesAnalyzerTest.scala:95) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 18.0 with 8 tasks resource profile 0
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.2.100:52933 in memory (size: 12.3 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 22) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 23) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7673 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 24) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 25) (192.168.2.100, executor driver, partition 4, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 5.0 in stage 18.0 (TID 26) (192.168.2.100, executor driver, partition 5, PROCESS_LOCAL, 7673 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 6.0 in stage 18.0 (TID 27) (192.168.2.100, executor driver, partition 6, PROCESS_LOCAL, 7632 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 7.0 in stage 18.0 (TID 28) (192.168.2.100, executor driver, partition 7, PROCESS_LOCAL, 7673 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 1.0 in stage 18.0 (TID 22)
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
25/08/08 05:37:07 INFO Executor: Running task 2.0 in stage 18.0 (TID 23)
25/08/08 05:37:07 INFO Executor: Running task 4.0 in stage 18.0 (TID 25)
25/08/08 05:37:07 INFO Executor: Running task 3.0 in stage 18.0 (TID 24)
25/08/08 05:37:07 INFO Executor: Running task 5.0 in stage 18.0 (TID 26)
25/08/08 05:37:07 INFO Executor: Running task 6.0 in stage 18.0 (TID 27)
25/08/08 05:37:07 INFO Executor: Running task 7.0 in stage 18.0 (TID 28)
25/08/08 05:37:07 INFO Executor: Finished task 4.0 in stage 18.0 (TID 25). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO Executor: Finished task 1.0 in stage 18.0 (TID 22). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO Executor: Finished task 5.0 in stage 18.0 (TID 26). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 4.0 in stage 18.0 (TID 25) in 11 ms on 192.168.2.100 (executor driver) (1/8)
25/08/08 05:37:07 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 22) in 12 ms on 192.168.2.100 (executor driver) (2/8)
25/08/08 05:37:07 INFO TaskSetManager: Finished task 5.0 in stage 18.0 (TID 26) in 11 ms on 192.168.2.100 (executor driver) (3/8)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 13 ms on 192.168.2.100 (executor driver) (4/8)
25/08/08 05:37:07 INFO Executor: Finished task 3.0 in stage 18.0 (TID 24). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 24) in 13 ms on 192.168.2.100 (executor driver) (5/8)
25/08/08 05:37:07 INFO Executor: Finished task 6.0 in stage 18.0 (TID 27). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 6.0 in stage 18.0 (TID 27) in 14 ms on 192.168.2.100 (executor driver) (6/8)
25/08/08 05:37:07 INFO Executor: Finished task 7.0 in stage 18.0 (TID 28). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 7.0 in stage 18.0 (TID 28) in 15 ms on 192.168.2.100 (executor driver) (7/8)
25/08/08 05:37:07 INFO Executor: Finished task 2.0 in stage 18.0 (TID 23). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 23) in 18 ms on 192.168.2.100 (executor driver) (8/8)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 18 (count at ForbesAnalyzerTest.scala:95) finished in 0.024 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet(ResultStage 19)
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[46] at count at ForbesAnalyzerTest.scala:95), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 16.7 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.2.100:52933 (size: 7.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[46] at count at ForbesAnalyzerTest.scala:95) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 29) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 19.0 (TID 29)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 8 (600.0 B) non-empty blocks including 8 (600.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 19.0 (TID 29). 2844 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 29) in 5 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 19 (count at ForbesAnalyzerTest.scala:95) finished in 0.007 s
25/08/08 05:37:07 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 12 finished: count at ForbesAnalyzerTest.scala:95, took 0.032951 s
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 3.625208 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 1.797583 ms
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 1.645 ms
25/08/08 05:37:07 INFO SparkContext: Starting job: count at ForbesAnalyzerTest.scala:98
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 50 (count at ForbesAnalyzerTest.scala:98) as input to shuffle 7
25/08/08 05:37:07 INFO DAGScheduler: Got job 13 (count at ForbesAnalyzerTest.scala:98) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 21 (count at ForbesAnalyzerTest.scala:98)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[50] at count at ForbesAnalyzerTest.scala:98), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 11.9 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.2.100:52933 (size: 5.7 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.2.100:52933 in memory (size: 7.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[50] at count at ForbesAnalyzerTest.scala:98) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 20.0 with 8 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 30) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7656 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 31) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7656 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 32) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7721 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 33) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7656 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 34) (192.168.2.100, executor driver, partition 4, PROCESS_LOCAL, 7664 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.2.100:52933 in memory (size: 5.7 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 35) (192.168.2.100, executor driver, partition 5, PROCESS_LOCAL, 7721 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 36) (192.168.2.100, executor driver, partition 6, PROCESS_LOCAL, 7656 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 37) (192.168.2.100, executor driver, partition 7, PROCESS_LOCAL, 7721 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 20.0 (TID 30)
25/08/08 05:37:07 INFO Executor: Running task 1.0 in stage 20.0 (TID 31)
25/08/08 05:37:07 INFO Executor: Running task 3.0 in stage 20.0 (TID 33)
25/08/08 05:37:07 INFO Executor: Running task 4.0 in stage 20.0 (TID 34)
25/08/08 05:37:07 INFO Executor: Running task 5.0 in stage 20.0 (TID 35)
25/08/08 05:37:07 INFO Executor: Running task 6.0 in stage 20.0 (TID 36)
25/08/08 05:37:07 INFO Executor: Running task 7.0 in stage 20.0 (TID 37)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 20.0 (TID 30). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO Executor: Running task 2.0 in stage 20.0 (TID 32)
25/08/08 05:37:07 INFO Executor: Finished task 7.0 in stage 20.0 (TID 37). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO Executor: Finished task 6.0 in stage 20.0 (TID 36). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 30) in 9 ms on 192.168.2.100 (executor driver) (1/8)
25/08/08 05:37:07 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 37) in 9 ms on 192.168.2.100 (executor driver) (2/8)
25/08/08 05:37:07 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 36) in 9 ms on 192.168.2.100 (executor driver) (3/8)
25/08/08 05:37:07 INFO Executor: Finished task 5.0 in stage 20.0 (TID 35). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO Executor: Finished task 1.0 in stage 20.0 (TID 31). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 35) in 11 ms on 192.168.2.100 (executor driver) (4/8)
25/08/08 05:37:07 INFO Executor: Finished task 3.0 in stage 20.0 (TID 33). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 31) in 12 ms on 192.168.2.100 (executor driver) (5/8)
25/08/08 05:37:07 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 33) in 12 ms on 192.168.2.100 (executor driver) (6/8)
25/08/08 05:37:07 INFO Executor: Finished task 2.0 in stage 20.0 (TID 32). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 32) in 13 ms on 192.168.2.100 (executor driver) (7/8)
25/08/08 05:37:07 INFO Executor: Finished task 4.0 in stage 20.0 (TID 34). 2190 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 34) in 13 ms on 192.168.2.100 (executor driver) (8/8)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 20 (count at ForbesAnalyzerTest.scala:98) finished in 0.021 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet(ResultStage 21)
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[54] at count at ForbesAnalyzerTest.scala:98), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 17.5 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.2.100:52933 (size: 7.9 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at count at ForbesAnalyzerTest.scala:98) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 38) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 21.0 (TID 38)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 8 (851.0 B) non-empty blocks including 8 (851.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 21.0 (TID 38). 2900 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 38) in 6 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 21 (count at ForbesAnalyzerTest.scala:98) finished in 0.009 s
25/08/08 05:37:07 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 13 finished: count at ForbesAnalyzerTest.scala:98, took 0.032016 s

25/08/08 05:37:07 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:07 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:07 INFO BlockManager: BlockManager stopped
25/08/08 05:37:07 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:07 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:07 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:07 INFO ResourceUtils: ==============================================================
25/08/08 05:37:07 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:07 INFO ResourceUtils: ==============================================================
25/08/08 05:37:07 INFO SparkContext: Submitted application: TransactionAnalyzer-Test
25/08/08 05:37:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:07 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:07 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:07 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:07 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:07 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:07 INFO Utils: Successfully started service 'sparkDriver' on port 52936.
25/08/08 05:37:07 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:07 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:07 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-4d792b1c-6a14-40f5-b5df-ca73b7b27810
25/08/08 05:37:07 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:07 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52937.
25/08/08 05:37:07 INFO NettyBlockTransferService: Server created on 192.168.2.100:52937
25/08/08 05:37:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52937, None)
25/08/08 05:37:07 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52937 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52937, None)
25/08/08 05:37:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52937, None)
25/08/08 05:37:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52937, None)

25/08/08 05:37:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:07 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:07 INFO CodeGenerator: Code generated in 2.1815 ms
25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 2 (count at TransactionAnalyzerTest.scala:43) as input to shuffle 0
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 0 (count at TransactionAnalyzerTest.scala:43) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at TransactionAnalyzerTest.scala:43)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at TransactionAnalyzerTest.scala:43), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at TransactionAnalyzerTest.scala:43) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1928 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 0 (count at TransactionAnalyzerTest.scala:43) finished in 0.022 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO SparkContext: Starting job: count at TransactionAnalyzerTest.scala:43
25/08/08 05:37:07 INFO DAGScheduler: Got job 1 (count at TransactionAnalyzerTest.scala:43) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 2 (count at TransactionAnalyzerTest.scala:43)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at TransactionAnalyzerTest.scala:43), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at TransactionAnalyzerTest.scala:43) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.2.100:52937 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2745 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 4 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 2 (count at TransactionAnalyzerTest.scala:43) finished in 0.011 s
25/08/08 05:37:07 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 1 finished: count at TransactionAnalyzerTest.scala:43, took 0.012762 s


25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 8 (count at TransactionAnalyzerTest.scala:60) as input to shuffle 1
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 2 (count at TransactionAnalyzerTest.scala:60) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at TransactionAnalyzerTest.scala:60)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at TransactionAnalyzerTest.scala:60), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at TransactionAnalyzerTest.scala:60) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 1885 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 4 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 3 (count at TransactionAnalyzerTest.scala:60) finished in 0.005 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO SparkContext: Starting job: count at TransactionAnalyzerTest.scala:60
25/08/08 05:37:07 INFO DAGScheduler: Got job 3 (count at TransactionAnalyzerTest.scala:60) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 5 (count at TransactionAnalyzerTest.scala:60)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at TransactionAnalyzerTest.scala:60), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at TransactionAnalyzerTest.scala:60) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 2659 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 5 (count at TransactionAnalyzerTest.scala:60) finished in 0.005 s
25/08/08 05:37:07 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 3 finished: count at TransactionAnalyzerTest.scala:60, took 0.005902 s


25/08/08 05:37:07 INFO DAGScheduler: Registering RDD 14 (count at TransactionAnalyzerTest.scala:76) as input to shuffle 2
25/08/08 05:37:07 INFO DAGScheduler: Got map stage job 4 (count at TransactionAnalyzerTest.scala:76) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at TransactionAnalyzerTest.scala:76)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[14] at count at TransactionAnalyzerTest.scala:76), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[14] at count at TransactionAnalyzerTest.scala:76) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 1885 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ShuffleMapStage 6 (count at TransactionAnalyzerTest.scala:76) finished in 0.005 s
25/08/08 05:37:07 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:07 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:07 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:07 INFO SparkContext: Starting job: count at TransactionAnalyzerTest.scala:76
25/08/08 05:37:07 INFO DAGScheduler: Got job 5 (count at TransactionAnalyzerTest.scala:76) with 1 output partitions
25/08/08 05:37:07 INFO DAGScheduler: Final stage: ResultStage 8 (count at TransactionAnalyzerTest.scala:76)
25/08/08 05:37:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/08/08 05:37:07 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:07 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at count at TransactionAnalyzerTest.scala:76), which has no missing parents
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at count at TransactionAnalyzerTest.scala:76) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/08/08 05:37:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:07 INFO Executor: Running task 0.0 in stage 8.0 (TID 5)
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:07 INFO Executor: Finished task 0.0 in stage 8.0 (TID 5). 2659 bytes result sent to driver
25/08/08 05:37:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 2 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:07 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/08/08 05:37:07 INFO DAGScheduler: ResultStage 8 (count at TransactionAnalyzerTest.scala:76) finished in 0.004 s
25/08/08 05:37:07 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/08/08 05:37:07 INFO DAGScheduler: Job 5 finished: count at TransactionAnalyzerTest.scala:76, took 0.004821 s


25/08/08 05:37:08 INFO DAGScheduler: Registering RDD 20 (count at TransactionAnalyzerTest.scala:93) as input to shuffle 3
25/08/08 05:37:08 INFO DAGScheduler: Got map stage job 6 (count at TransactionAnalyzerTest.scala:93) with 2 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (count at TransactionAnalyzerTest.scala:93)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[20] at count at TransactionAnalyzerTest.scala:93), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[20] at count at TransactionAnalyzerTest.scala:93) (first 15 tasks are for partitions Vector(0, 1))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
25/08/08 05:37:08 INFO Executor: Running task 1.0 in stage 9.0 (TID 7)
25/08/08 05:37:08 INFO Executor: Finished task 1.0 in stage 9.0 (TID 7). 1928 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 4 ms on 192.168.2.100 (executor driver) (1/2)
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 1928 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 4 ms on 192.168.2.100 (executor driver) (2/2)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ShuffleMapStage 9 (count at TransactionAnalyzerTest.scala:93) finished in 0.006 s
25/08/08 05:37:08 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:08 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:08 INFO SparkContext: Starting job: count at TransactionAnalyzerTest.scala:93
25/08/08 05:37:08 INFO DAGScheduler: Got job 7 (count at TransactionAnalyzerTest.scala:93) with 1 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ResultStage 11 (count at TransactionAnalyzerTest.scala:93)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[23] at count at TransactionAnalyzerTest.scala:93), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.2.100:52937 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[23] at count at TransactionAnalyzerTest.scala:93) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/08/08 05:37:08 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.2.100:52937 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 11.0 (TID 8)
25/08/08 05:37:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.2.100:52937 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.2.100:52937 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 11.0 (TID 8). 2659 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ResultStage 11 (count at TransactionAnalyzerTest.scala:93) finished in 0.007 s
25/08/08 05:37:08 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/08/08 05:37:08 INFO DAGScheduler: Job 7 finished: count at TransactionAnalyzerTest.scala:93, took 0.007672 s
25/08/08 05:37:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.2.100:52937 in memory (size: 5.6 KiB, free: 3.4 GiB)

25/08/08 05:37:08 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.2.100:52937 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:08 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:08 INFO BlockManager: BlockManager stopped
25/08/08 05:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:08 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:08 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO SparkContext: Submitted application: TransactionSearch-Test
25/08/08 05:37:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:08 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:08 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:08 INFO Utils: Successfully started service 'sparkDriver' on port 52938.
25/08/08 05:37:08 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:08 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-25f62407-948a-496c-87e6-7866fed0a327
25/08/08 05:37:08 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:08 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52939.
25/08/08 05:37:08 INFO NettyBlockTransferService: Server created on 192.168.2.100:52939
25/08/08 05:37:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52939, None)
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52939 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52939, None)
25/08/08 05:37:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52939, None)
25/08/08 05:37:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52939, None)

25/08/08 05:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:08 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 2.14275 ms
25/08/08 05:37:08 INFO DAGScheduler: Registering RDD 2 (count at TransactionSearchTest.scala:49) as input to shuffle 0
25/08/08 05:37:08 INFO DAGScheduler: Got map stage job 0 (count at TransactionSearchTest.scala:49) with 3 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at TransactionSearchTest.scala:49)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at TransactionSearchTest.scala:49), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52939 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at TransactionSearchTest.scala:49) (first 15 tasks are for partitions Vector(0, 1, 2))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:08 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
25/08/08 05:37:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1928 bytes result sent to driver
25/08/08 05:37:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1928 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4 ms on 192.168.2.100 (executor driver) (1/3)
25/08/08 05:37:08 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1928 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4 ms on 192.168.2.100 (executor driver) (2/3)
25/08/08 05:37:08 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 5 ms on 192.168.2.100 (executor driver) (3/3)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ShuffleMapStage 0 (count at TransactionSearchTest.scala:49) finished in 0.008 s
25/08/08 05:37:08 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:08 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:08 INFO SparkContext: Starting job: count at TransactionSearchTest.scala:49
25/08/08 05:37:08 INFO DAGScheduler: Got job 1 (count at TransactionSearchTest.scala:49) with 1 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ResultStage 2 (count at TransactionSearchTest.scala:49)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at TransactionSearchTest.scala:49), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52939 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at TransactionSearchTest.scala:49) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 2702 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 2 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ResultStage 2 (count at TransactionSearchTest.scala:49) finished in 0.004 s
25/08/08 05:37:08 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/08/08 05:37:08 INFO DAGScheduler: Job 1 finished: count at TransactionSearchTest.scala:49, took 0.004880 s


25/08/08 05:37:08 INFO CodeGenerator: Code generated in 1.737042 ms
25/08/08 05:37:08 INFO DAGScheduler: Registering RDD 8 (count at TransactionSearchTest.scala:72) as input to shuffle 1
25/08/08 05:37:08 INFO DAGScheduler: Got map stage job 2 (count at TransactionSearchTest.scala:72) with 6 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at TransactionSearchTest.scala:72)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at TransactionSearchTest.scala:72), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52939 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at TransactionSearchTest.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 6 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 6) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 7) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 8) (192.168.2.100, executor driver, partition 4, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 9) (192.168.2.100, executor driver, partition 5, PROCESS_LOCAL, 7608 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
25/08/08 05:37:08 INFO Executor: Running task 2.0 in stage 3.0 (TID 6)
25/08/08 05:37:08 INFO Executor: Running task 1.0 in stage 3.0 (TID 5)
25/08/08 05:37:08 INFO Executor: Running task 3.0 in stage 3.0 (TID 7)
25/08/08 05:37:08 INFO Executor: Running task 4.0 in stage 3.0 (TID 8)
25/08/08 05:37:08 INFO Executor: Running task 5.0 in stage 3.0 (TID 9)
25/08/08 05:37:08 INFO Executor: Finished task 3.0 in stage 3.0 (TID 7). 1928 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 7) in 4 ms on 192.168.2.100 (executor driver) (1/6)
25/08/08 05:37:08 INFO Executor: Finished task 2.0 in stage 3.0 (TID 6). 1885 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 6) in 4 ms on 192.168.2.100 (executor driver) (2/6)
25/08/08 05:37:08 INFO Executor: Finished task 4.0 in stage 3.0 (TID 8). 1885 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 8) in 5 ms on 192.168.2.100 (executor driver) (3/6)
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1885 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 5 ms on 192.168.2.100 (executor driver) (4/6)
25/08/08 05:37:08 INFO Executor: Finished task 1.0 in stage 3.0 (TID 5). 1885 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 6 ms on 192.168.2.100 (executor driver) (5/6)
25/08/08 05:37:08 INFO Executor: Finished task 5.0 in stage 3.0 (TID 9). 1885 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 9) in 6 ms on 192.168.2.100 (executor driver) (6/6)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ShuffleMapStage 3 (count at TransactionSearchTest.scala:72) finished in 0.008 s
25/08/08 05:37:08 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:08 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:08 INFO SparkContext: Starting job: count at TransactionSearchTest.scala:72
25/08/08 05:37:08 INFO DAGScheduler: Got job 3 (count at TransactionSearchTest.scala:72) with 1 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ResultStage 5 (count at TransactionSearchTest.scala:72)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at TransactionSearchTest.scala:72), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52939 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at TransactionSearchTest.scala:72) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 10)
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Getting 6 (360.0 B) non-empty blocks including 6 (360.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 10). 2702 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 5 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ResultStage 5 (count at TransactionSearchTest.scala:72) finished in 0.007 s
25/08/08 05:37:08 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/08/08 05:37:08 INFO DAGScheduler: Job 3 finished: count at TransactionSearchTest.scala:72, took 0.007474 s

25/08/08 05:37:08 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:08 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:08 INFO BlockManager: BlockManager stopped
25/08/08 05:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:08 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:08 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO SparkContext: Submitted application: TweetsAnalyzer-Test
25/08/08 05:37:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:08 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:08 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:08 INFO Utils: Successfully started service 'sparkDriver' on port 52940.
25/08/08 05:37:08 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:08 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-04f48cf7-0705-471f-a574-d9bd922af8f0
25/08/08 05:37:08 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:08 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52941.
25/08/08 05:37:08 INFO NettyBlockTransferService: Server created on 192.168.2.100:52941
25/08/08 05:37:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52941, None)
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52941 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52941, None)
25/08/08 05:37:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52941, None)
25/08/08 05:37:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52941, None)

25/08/08 05:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:08 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 15.950167 ms
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 8.48175 ms
25/08/08 05:37:08 INFO DAGScheduler: Registering RDD 2 (head at TweetsAnalyzerTest.scala:43) as input to shuffle 0
25/08/08 05:37:08 INFO DAGScheduler: Got map stage job 0 (head at TweetsAnalyzerTest.scala:43) with 5 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (head at TweetsAnalyzerTest.scala:43)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at head at TweetsAnalyzerTest.scala:43), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 28.5 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.5 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52941 (size: 12.5 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at head at TweetsAnalyzerTest.scala:43) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7720 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7672 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7784 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7664 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (192.168.2.100, executor driver, partition 4, PROCESS_LOCAL, 7624 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
25/08/08 05:37:08 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
25/08/08 05:37:08 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
25/08/08 05:37:08 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
25/08/08 05:37:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2526 bytes result sent to driver
25/08/08 05:37:08 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2526 bytes result sent to driver
25/08/08 05:37:08 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2526 bytes result sent to driver
25/08/08 05:37:08 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2526 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 20 ms on 192.168.2.100 (executor driver) (1/5)
25/08/08 05:37:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 21 ms on 192.168.2.100 (executor driver) (2/5)
25/08/08 05:37:08 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 21 ms on 192.168.2.100 (executor driver) (3/5)
25/08/08 05:37:08 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 20 ms on 192.168.2.100 (executor driver) (4/5)
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2655 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 25 ms on 192.168.2.100 (executor driver) (5/5)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ShuffleMapStage 0 (head at TweetsAnalyzerTest.scala:43) finished in 0.027 s
25/08/08 05:37:08 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:08 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:08 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/08/08 05:37:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 6.489375 ms
25/08/08 05:37:08 INFO SparkContext: Starting job: head at TweetsAnalyzerTest.scala:43
25/08/08 05:37:08 INFO DAGScheduler: Got job 1 (head at TweetsAnalyzerTest.scala:43) with 1 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ResultStage 2 (head at TweetsAnalyzerTest.scala:43)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at head at TweetsAnalyzerTest.scala:43), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 28.2 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.5 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52941 (size: 12.5 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at head at TweetsAnalyzerTest.scala:43) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 3755 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 6 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ResultStage 2 (head at TweetsAnalyzerTest.scala:43) finished in 0.007 s
25/08/08 05:37:08 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/08/08 05:37:08 INFO DAGScheduler: Job 1 finished: head at TweetsAnalyzerTest.scala:43, took 0.041619 s
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 3.684292 ms
25/08/08 05:37:08 INFO DAGScheduler: Registering RDD 8 (head at TweetsAnalyzerTest.scala:44) as input to shuffle 1
25/08/08 05:37:08 INFO DAGScheduler: Got map stage job 2 (head at TweetsAnalyzerTest.scala:44) with 5 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (head at TweetsAnalyzerTest.scala:44)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at head at TweetsAnalyzerTest.scala:44), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 28.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52941 (size: 12.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at head at TweetsAnalyzerTest.scala:44) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7720 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7) (192.168.2.100, executor driver, partition 1, PROCESS_LOCAL, 7672 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8) (192.168.2.100, executor driver, partition 2, PROCESS_LOCAL, 7784 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9) (192.168.2.100, executor driver, partition 3, PROCESS_LOCAL, 7664 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 10) (192.168.2.100, executor driver, partition 4, PROCESS_LOCAL, 7624 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
25/08/08 05:37:08 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
25/08/08 05:37:08 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
25/08/08 05:37:08 INFO Executor: Running task 4.0 in stage 3.0 (TID 10)
25/08/08 05:37:08 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
25/08/08 05:37:08 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2483 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 6 ms on 192.168.2.100 (executor driver) (1/5)
25/08/08 05:37:08 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2483 bytes result sent to driver
25/08/08 05:37:08 INFO Executor: Finished task 4.0 in stage 3.0 (TID 10). 2483 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 6 ms on 192.168.2.100 (executor driver) (2/5)
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2483 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 10) in 7 ms on 192.168.2.100 (executor driver) (3/5)
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 8 ms on 192.168.2.100 (executor driver) (4/5)
25/08/08 05:37:08 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2612 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 9 ms on 192.168.2.100 (executor driver) (5/5)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ShuffleMapStage 3 (head at TweetsAnalyzerTest.scala:44) finished in 0.011 s
25/08/08 05:37:08 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:08 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:08 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:08 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/08/08 05:37:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/08/08 05:37:08 INFO SparkContext: Starting job: head at TweetsAnalyzerTest.scala:44
25/08/08 05:37:08 INFO DAGScheduler: Got job 3 (head at TweetsAnalyzerTest.scala:44) with 1 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ResultStage 5 (head at TweetsAnalyzerTest.scala:44)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at head at TweetsAnalyzerTest.scala:44), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 28.3 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52941 (size: 12.6 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at head at TweetsAnalyzerTest.scala:44) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 3755 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ResultStage 5 (head at TweetsAnalyzerTest.scala:44) finished in 0.004 s
25/08/08 05:37:08 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/08/08 05:37:08 INFO DAGScheduler: Job 3 finished: head at TweetsAnalyzerTest.scala:44, took 0.005380 s

25/08/08 05:37:08 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:08 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:08 INFO BlockManager: BlockManager stopped
25/08/08 05:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:08 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:08 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO SparkContext: Submitted application: ForbesCleaner-Test
25/08/08 05:37:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:08 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:08 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:08 INFO Utils: Successfully started service 'sparkDriver' on port 52942.
25/08/08 05:37:08 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:08 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-188ec841-d7a1-4397-a759-98ac688c039e
25/08/08 05:37:08 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:08 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52943.
25/08/08 05:37:08 INFO NettyBlockTransferService: Server created on 192.168.2.100:52943
25/08/08 05:37:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52943, None)
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52943 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52943, None)
25/08/08 05:37:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52943, None)
25/08/08 05:37:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52943, None)
25/08/08 05:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:08 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.


25/08/08 05:37:08 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:08 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:08 INFO BlockManager: BlockManager stopped
25/08/08 05:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:08 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:08 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO SparkContext: Submitted application: TransactionCleanerTest
25/08/08 05:37:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:08 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:08 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:08 INFO Utils: Successfully started service 'sparkDriver' on port 52944.
25/08/08 05:37:08 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:08 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-239f3423-fdf0-49a8-9094-de65cca3737f
25/08/08 05:37:08 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:08 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52945.
25/08/08 05:37:08 INFO NettyBlockTransferService: Server created on 192.168.2.100:52945
25/08/08 05:37:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52945, None)
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52945 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52945, None)
25/08/08 05:37:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52945, None)
25/08/08 05:37:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52945, None)
25/08/08 05:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:08 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.

25/08/08 05:37:08 INFO CodeGenerator: Code generated in 2.248167 ms

25/08/08 05:37:08 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:08 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:08 INFO BlockManager: BlockManager stopped
25/08/08 05:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:08 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:08 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO SparkContext: Submitted application: TweetsCleanerTest
25/08/08 05:37:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:08 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:08 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:08 INFO Utils: Successfully started service 'sparkDriver' on port 52946.
25/08/08 05:37:08 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:08 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-78e05720-4fcf-40f2-9cf9-05fc285abbed
25/08/08 05:37:08 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:08 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52947.
25/08/08 05:37:08 INFO NettyBlockTransferService: Server created on 192.168.2.100:52947
25/08/08 05:37:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52947, None)
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52947 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52947, None)
25/08/08 05:37:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52947, None)
25/08/08 05:37:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52947, None)
25/08/08 05:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:08 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.

25/08/08 05:37:08 INFO CodeGenerator: Code generated in 2.5225 ms
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 4.275 ms

25/08/08 05:37:08 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:08 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:08 INFO BlockManager: BlockManager stopped
25/08/08 05:37:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:08 INFO SparkContext: Successfully stopped SparkContext



25/08/08 05:37:08 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:08 INFO ResourceUtils: ==============================================================
25/08/08 05:37:08 INFO SparkContext: Submitted application: Test
25/08/08 05:37:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:08 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:08 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:08 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:08 INFO Utils: Successfully started service 'sparkDriver' on port 52948.
25/08/08 05:37:08 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:08 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-d088f99f-6b45-40a2-8007-da2844543bb4
25/08/08 05:37:08 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:08 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52949.
25/08/08 05:37:08 INFO NettyBlockTransferService: Server created on 192.168.2.100:52949
25/08/08 05:37:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52949, None)
25/08/08 05:37:08 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52949 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52949, None)
25/08/08 05:37:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52949, None)
25/08/08 05:37:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52949, None)
25/08/08 05:37:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:08 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:08 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/08/08 05:37:08 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:08 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:08 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1004, None)) > 0)
25/08/08 05:37:08 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 3.027792 ms
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52949 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 0 from csv at ForbesLoader.scala:15
25/08/08 05:37:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:08 INFO SparkContext: Starting job: csv at ForbesLoader.scala:15
25/08/08 05:37:08 INFO DAGScheduler: Got job 0 (csv at ForbesLoader.scala:15) with 1 output partitions
25/08/08 05:37:08 INFO DAGScheduler: Final stage: ResultStage 0 (csv at ForbesLoader.scala:15)
25/08/08 05:37:08 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:08 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at ForbesLoader.scala:15), which has no missing parents
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52949 (size: 6.0 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at ForbesLoader.scala:15) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/08/08 05:37:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7942 bytes) taskResourceAssignments Map()
25/08/08 05:37:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:08 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/forbes_2022_billionaires.csv, range: 0-1992566, partition values: [empty row]
25/08/08 05:37:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1803 bytes result sent to driver
25/08/08 05:37:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 35 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:08 INFO DAGScheduler: ResultStage 0 (csv at ForbesLoader.scala:15) finished in 0.044 s
25/08/08 05:37:08 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/08/08 05:37:08 INFO DAGScheduler: Job 0 finished: csv at ForbesLoader.scala:15, took 0.044968 s
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 1.659833 ms
25/08/08 05:37:08 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:08 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:08 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52949 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:08 INFO SparkContext: Created broadcast 2 from csv at ForbesLoader.scala:15
25/08/08 05:37:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:08 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:08 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:08 INFO FileSourceStrategy: Output Data Schema: struct<>
25/08/08 05:37:08 INFO CodeGenerator: Code generated in 3.40625 ms
25/08/08 05:37:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52949 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 3 from count at ForbesLoaderTest.scala:25
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO DAGScheduler: Registering RDD 13 (count at ForbesLoaderTest.scala:25) as input to shuffle 0
25/08/08 05:37:09 INFO DAGScheduler: Got map stage job 1 (count at ForbesLoaderTest.scala:25) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at ForbesLoaderTest.scala:25)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at ForbesLoaderTest.scala:25), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.5 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.2.100:52949 (size: 8.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at ForbesLoaderTest.scala:25) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7931 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/forbes_2022_billionaires.csv, range: 0-1992566, partition values: [empty row]
25/08/08 05:37:09 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.2.100:52949 in memory (size: 6.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.2.100:52949 in memory (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2057 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ShuffleMapStage 1 (count at ForbesLoaderTest.scala:25) finished in 0.047 s
25/08/08 05:37:09 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:09 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:09 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:09 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:09 INFO SparkContext: Starting job: count at ForbesLoaderTest.scala:25
25/08/08 05:37:09 INFO DAGScheduler: Got job 2 (count at ForbesLoaderTest.scala:25) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 3 (count at ForbesLoaderTest.scala:25)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at ForbesLoaderTest.scala:25), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.2.100:52949 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at ForbesLoaderTest.scala:25) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
25/08/08 05:37:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 2659 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 3 (count at ForbesLoaderTest.scala:25) finished in 0.004 s
25/08/08 05:37:09 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 2 finished: count at ForbesLoaderTest.scala:25, took 0.005102 s
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<>
25/08/08 05:37:09 INFO CodeGenerator: Code generated in 3.271166 ms
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.2.100:52949 in memory (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.2.100:52949 in memory (size: 8.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.2.100:52949 in memory (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.2.100:52949 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 6 from head at ForbesLoaderTest.scala:31
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: head at ForbesLoaderTest.scala:31
25/08/08 05:37:09 INFO DAGScheduler: Got job 3 (head at ForbesLoaderTest.scala:31) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 4 (head at ForbesLoaderTest.scala:31)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at head at ForbesLoaderTest.scala:31), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.5 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.2.100:52949 (size: 6.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at head at ForbesLoaderTest.scala:31) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7942 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/forbes_2022_billionaires.csv, range: 0-1992566, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 1513 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 4 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 4 (head at ForbesLoaderTest.scala:31) finished in 0.005 s
25/08/08 05:37:09 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 3 finished: head at ForbesLoaderTest.scala:31, took 0.006110 s
25/08/08 05:37:09 INFO CodeGenerator: Code generated in 2.036041 ms
25/08/08 05:37:09 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:09 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:09 INFO BlockManager: BlockManager stopped
25/08/08 05:37:09 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:09 INFO SparkContext: Successfully stopped SparkContext



25/08/08 05:37:09 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:09 INFO ResourceUtils: ==============================================================
25/08/08 05:37:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:09 INFO ResourceUtils: ==============================================================
25/08/08 05:37:09 INFO SparkContext: Submitted application: ETL-Project
25/08/08 05:37:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:09 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:09 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:09 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:09 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:09 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:09 INFO Utils: Successfully started service 'sparkDriver' on port 52950.
25/08/08 05:37:09 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:09 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:09 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-93ee4530-7e07-437a-a7b0-1a0f9c18907d
25/08/08 05:37:09 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:09 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52951.
25/08/08 05:37:09 INFO NettyBlockTransferService: Server created on 192.168.2.100:52951
25/08/08 05:37:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52951, None)
25/08/08 05:37:09 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52951 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52951, None)
25/08/08 05:37:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52951, None)
25/08/08 05:37:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52951, None)

25/08/08 05:37:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:09 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1137, None)) > 0)
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52951 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 0 from csv at TweetsLoader.scala:29
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9113514 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: csv at TweetsLoader.scala:29
25/08/08 05:37:09 INFO DAGScheduler: Got job 0 (csv at TweetsLoader.scala:29) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 0 (csv at TweetsLoader.scala:29)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TweetsLoader.scala:29), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52951 (size: 6.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TweetsLoader.scala:29) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/covid19_tweets.csv, range: 0-9113514, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1732 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 0 (csv at TweetsLoader.scala:29) finished in 0.008 s
25/08/08 05:37:09 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 0 finished: csv at TweetsLoader.scala:29, took 0.008625 s
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52951 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 2 from csv at TweetsLoader.scala:29
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9113514 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: atleastnnonnulls(14, user_name#1154, user_location#1155, user_description#1156, user_created#1157, user_followers#1158, user_friends#1159, user_favourites#1160, user_verified#1161, date#1162, text#1163, hashtags#1164, source#1165, is_retweet#1166, covid)
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<user_name: string, user_location: string, user_description: string, user_created: string, user_followers: string ... 11 more fields>
25/08/08 05:37:09 INFO CodeGenerator: Code generated in 3.519583 ms
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52951 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 3 from head at TweetsLoaderTest.scala:32
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9113514 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: head at TweetsLoaderTest.scala:32
25/08/08 05:37:09 INFO DAGScheduler: Got job 1 (head at TweetsLoaderTest.scala:32) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 1 (head at TweetsLoaderTest.scala:32)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at head at TweetsLoaderTest.scala:32), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.5 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.2.100:52951 (size: 8.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at head at TweetsLoaderTest.scala:32) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/covid19_tweets.csv, range: 0-9113514, partition values: [empty row]
25/08/08 05:37:09 INFO CodeGenerator: Code generated in 3.792583 ms
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1569 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 12 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 1 (head at TweetsLoaderTest.scala:32) finished in 0.014 s
25/08/08 05:37:09 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 1 finished: head at TweetsLoaderTest.scala:32, took 0.014873 s


25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1226, None)) > 0)
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.2.100:52951 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 5 from csv at TweetsLoader.scala:35
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: csv at TweetsLoader.scala:35
25/08/08 05:37:09 INFO DAGScheduler: Got job 2 (csv at TweetsLoader.scala:35) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 2 (csv at TweetsLoader.scala:35)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at csv at TweetsLoader.scala:35), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.2.100:52951 (size: 6.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at csv at TweetsLoader.scala:35) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7927 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/financial.csv, range: 0-4194304, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1628 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 2 (csv at TweetsLoader.scala:35) finished in 0.005 s
25/08/08 05:37:09 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 2 finished: csv at TweetsLoader.scala:35, took 0.005383 s
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.2.100:52951 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 7 from csv at TweetsLoader.scala:35
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.2.100:52951 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 8 from head at TweetsLoaderTest.scala:38
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: head at TweetsLoaderTest.scala:38
25/08/08 05:37:09 INFO DAGScheduler: Got job 3 (head at TweetsLoaderTest.scala:38) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 3 (head at TweetsLoaderTest.scala:38)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[27] at head at TweetsLoaderTest.scala:38), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.2.100:52951 (size: 6.5 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[27] at head at TweetsLoaderTest.scala:38) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7927 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/financial.csv, range: 0-4194304, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1513 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 3 (head at TweetsLoaderTest.scala:38) finished in 0.005 s
25/08/08 05:37:09 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 3 finished: head at TweetsLoaderTest.scala:38, took 0.005971 s


25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1273, None)) > 0)
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.2.100:52951 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 10 from csv at TweetsLoader.scala:40
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: csv at TweetsLoader.scala:40
25/08/08 05:37:09 INFO DAGScheduler: Got job 4 (csv at TweetsLoader.scala:40) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 4 (csv at TweetsLoader.scala:40)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[31] at csv at TweetsLoader.scala:40), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.2.100:52951 (size: 6.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[31] at csv at TweetsLoader.scala:40) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/GRAMMYs_tweets.csv, range: 0-3904639, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1689 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 4 (csv at TweetsLoader.scala:40) finished in 0.008 s
25/08/08 05:37:09 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 4 finished: csv at TweetsLoader.scala:40, took 0.008436 s
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.2.100:52951 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 12 from csv at TweetsLoader.scala:40
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: atleastnnonnulls(14, user_name#1290, user_location#1291, user_description#1292, user_created#1293, user_followers#1294, user_friends#1295, user_favourites#1296, user_verified#1297, date#1298, text#1299, hashtags#1300, source#1301, is_retweet#1302, grammys)
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<user_name: string, user_location: string, user_description: string, user_created: string, user_followers: string ... 11 more fields>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.2.100:52951 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 13 from head at TweetsLoaderTest.scala:44
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: head at TweetsLoaderTest.scala:44
25/08/08 05:37:09 INFO DAGScheduler: Got job 5 (head at TweetsLoaderTest.scala:44) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 5 (head at TweetsLoaderTest.scala:44)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[41] at head at TweetsLoaderTest.scala:44), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.5 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.2.100:52951 (size: 8.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[41] at head at TweetsLoaderTest.scala:44) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7932 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/GRAMMYs_tweets.csv, range: 0-3904639, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1569 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 5 (head at TweetsLoaderTest.scala:44) finished in 0.012 s
25/08/08 05:37:09 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 5 finished: head at TweetsLoaderTest.scala:44, took 0.012527 s

25/08/08 05:37:09 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:09 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:09 INFO BlockManager: BlockManager stopped
25/08/08 05:37:09 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:09 INFO SparkContext: Successfully stopped SparkContext


25/08/08 05:37:09 INFO SparkContext: Running Spark version 3.3.1
25/08/08 05:37:09 INFO ResourceUtils: ==============================================================
25/08/08 05:37:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/08/08 05:37:09 INFO ResourceUtils: ==============================================================
25/08/08 05:37:09 INFO SparkContext: Submitted application: ETL-Project
25/08/08 05:37:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/08/08 05:37:09 INFO ResourceProfile: Limiting resource is cpu
25/08/08 05:37:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/08/08 05:37:09 INFO SecurityManager: Changing view acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:09 INFO SecurityManager: Changing modify acls to: dhandapanidhandapaniyedappalli
25/08/08 05:37:09 INFO SecurityManager: Changing view acls groups to: 
25/08/08 05:37:09 INFO SecurityManager: Changing modify acls groups to: 
25/08/08 05:37:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dhandapanidhandapaniyedappalli); groups with view permissions: Set(); users  with modify permissions: Set(dhandapanidhandapaniyedappalli); groups with modify permissions: Set()
25/08/08 05:37:09 INFO Utils: Successfully started service 'sparkDriver' on port 52952.
25/08/08 05:37:09 INFO SparkEnv: Registering MapOutputTracker
25/08/08 05:37:09 INFO SparkEnv: Registering BlockManagerMaster
25/08/08 05:37:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/08/08 05:37:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/08/08 05:37:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/08/08 05:37:09 INFO DiskBlockManager: Created local directory at /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/blockmgr-91b81750-a919-4914-8700-5d7f357e395a
25/08/08 05:37:09 INFO MemoryStore: MemoryStore started with capacity 3.4 GiB
25/08/08 05:37:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/08/08 05:37:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/08/08 05:37:09 INFO Executor: Starting executor ID driver on host 192.168.2.100
25/08/08 05:37:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/08/08 05:37:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52953.
25/08/08 05:37:09 INFO NettyBlockTransferService: Server created on 192.168.2.100:52953
25/08/08 05:37:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/08/08 05:37:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.100, 52953, None)
25/08/08 05:37:09 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.100:52953 with 3.4 GiB RAM, BlockManagerId(driver, 192.168.2.100, 52953, None)
25/08/08 05:37:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.100, 52953, None)
25/08/08 05:37:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.2.100, 52953, None)

25/08/08 05:37:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/08/08 05:37:09 INFO SharedState: Warehouse path is 'file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1362, None)) > 0)
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.2.100:52953 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 0 from csv at TweetsUserLoader.scala:13
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: csv at TweetsUserLoader.scala:13
25/08/08 05:37:09 INFO DAGScheduler: Got job 0 (csv at TweetsUserLoader.scala:13) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 0 (csv at TweetsUserLoader.scala:13)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at TweetsUserLoader.scala:13), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.2.100:52953 (size: 6.0 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at TweetsUserLoader.scala:13) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7933 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/twitter_dataset.csv, range: 0-2713677, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1655 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 6 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 0 (csv at TweetsUserLoader.scala:13) finished in 0.008 s
25/08/08 05:37:09 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 0 finished: csv at TweetsUserLoader.scala:13, took 0.008875 s
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.2.100:52953 (size: 33.9 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 2 from csv at TweetsUserLoader.scala:13
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.2.100:52953 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 3 from count at TweetsUserLoaderTest.scala:34
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO DAGScheduler: Registering RDD 13 (count at TweetsUserLoaderTest.scala:34) as input to shuffle 0
25/08/08 05:37:09 INFO DAGScheduler: Got map stage job 1 (count at TweetsUserLoaderTest.scala:34) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at TweetsUserLoaderTest.scala:34)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at TweetsUserLoaderTest.scala:34), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.2.100:52953 (size: 8.4 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at TweetsUserLoaderTest.scala:34) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7922 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/twitter_dataset.csv, range: 0-2713677, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2014 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 22 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ShuffleMapStage 1 (count at TweetsUserLoaderTest.scala:34) finished in 0.024 s
25/08/08 05:37:09 INFO DAGScheduler: looking for newly runnable stages
25/08/08 05:37:09 INFO DAGScheduler: running: HashSet()
25/08/08 05:37:09 INFO DAGScheduler: waiting: HashSet()
25/08/08 05:37:09 INFO DAGScheduler: failed: HashSet()
25/08/08 05:37:09 INFO SparkContext: Starting job: count at TweetsUserLoaderTest.scala:34
25/08/08 05:37:09 INFO DAGScheduler: Got job 2 (count at TweetsUserLoaderTest.scala:34) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 3 (count at TweetsUserLoaderTest.scala:34)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at TweetsUserLoaderTest.scala:34), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.6 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.2.100:52953 (size: 5.6 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at TweetsUserLoaderTest.scala:34) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (192.168.2.100, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
25/08/08 05:37:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/08/08 05:37:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 2659 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 2 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 3 (count at TweetsUserLoaderTest.scala:34) finished in 0.003 s
25/08/08 05:37:09 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 2 finished: count at TweetsUserLoaderTest.scala:34, took 0.004054 s
25/08/08 05:37:09 INFO FileSourceStrategy: Pushed Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/08/08 05:37:09 INFO FileSourceStrategy: Output Data Schema: struct<>
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 376.0 B, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.2.100:52953 (size: 33.8 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 6 from head at TweetsUserLoaderTest.scala:38
25/08/08 05:37:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/08/08 05:37:09 INFO SparkContext: Starting job: head at TweetsUserLoaderTest.scala:38
25/08/08 05:37:09 INFO DAGScheduler: Got job 3 (head at TweetsUserLoaderTest.scala:38) with 1 output partitions
25/08/08 05:37:09 INFO DAGScheduler: Final stage: ResultStage 4 (head at TweetsUserLoaderTest.scala:38)
25/08/08 05:37:09 INFO DAGScheduler: Parents of final stage: List()
25/08/08 05:37:09 INFO DAGScheduler: Missing parents: List()
25/08/08 05:37:09 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at head at TweetsUserLoaderTest.scala:38), which has no missing parents
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.8 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 3.4 GiB)
25/08/08 05:37:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.2.100:52953 (size: 6.5 KiB, free: 3.4 GiB)
25/08/08 05:37:09 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
25/08/08 05:37:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at head at TweetsUserLoaderTest.scala:38) (first 15 tasks are for partitions Vector(0))
25/08/08 05:37:09 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/08/08 05:37:09 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (192.168.2.100, executor driver, partition 0, PROCESS_LOCAL, 7933 bytes) taskResourceAssignments Map()
25/08/08 05:37:09 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
25/08/08 05:37:09 INFO FileScanRDD: Reading File path: file:///Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/Datasource/twitter_dataset.csv, range: 0-2713677, partition values: [empty row]
25/08/08 05:37:09 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 1513 bytes result sent to driver
25/08/08 05:37:09 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 3 ms on 192.168.2.100 (executor driver) (1/1)
25/08/08 05:37:09 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/08/08 05:37:09 INFO DAGScheduler: ResultStage 4 (head at TweetsUserLoaderTest.scala:38) finished in 0.005 s
25/08/08 05:37:09 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/08/08 05:37:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/08/08 05:37:09 INFO DAGScheduler: Job 3 finished: head at TweetsUserLoaderTest.scala:38, took 0.004881 s

25/08/08 05:37:09 INFO SparkUI: Stopped Spark web UI at http://192.168.2.100:4040
25/08/08 05:37:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/08/08 05:37:09 INFO MemoryStore: MemoryStore cleared
25/08/08 05:37:09 INFO BlockManager: BlockManager stopped
25/08/08 05:37:09 INFO BlockManagerMaster: BlockManagerMaster stopped
25/08/08 05:37:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/08/08 05:37:09 INFO SparkContext: Successfully stopped SparkContext

25/08/08 05:37:09 INFO ShutdownHookManager: Shutdown hook called
25/08/08 05:37:09 INFO ShutdownHookManager: Deleting directory /private/var/folders/f4/z0ldslyx61sb6v_x8zg2snvw0000gn/T/spark-30b4960d-2864-4a2b-8f20-f499fb1c54



file:/Users/dhandapanidhandapaniyedappalli/Downloads/Project-Spark-Scala-ETL-master/spark-warehouse'.
